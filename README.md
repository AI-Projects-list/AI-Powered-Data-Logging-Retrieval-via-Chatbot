# ðŸ§  AI-Powered Data Logging & Retrieval via Chatbot

An AI system that:
- Records **video**, **images**, and **text** logs
- Stores them in a **database and/or GCP Storage**
- Embeds logs for semantic search
- Allows **chatbot-based querying** via **OpenAI or Ollama LLM**
- Supports **face recognition** and **motion detection**
- Deploys to **Render (backend)** and **Vercel (frontend)**

---

## ðŸ“¦ Features

| Feature                        | Description |
|-------------------------------|-------------|
| ðŸŽ¥ Video/Image Capture        | Capture from camera in real-time |
| ðŸ“ Text Logging               | Manual input or event-based logs |
| ðŸ§  LLM Chatbot                | Ask chatbot to retrieve matching logs |
| ðŸ“‚ GCP Storage Support        | Store media files on Google Cloud |
| ðŸ”Ž Semantic Search            | Embedding-based search via FAISS (optional) |
| ðŸ§ Face Recognition           | Face detection with OpenCV |
| ðŸŽžï¸ Motion Detection          | Detect activity via frame deltas |
| ðŸ§  Dual LLM Support           | Use OpenAI API or local Ollama LLM |
| ðŸŒ Web App                    | Frontend with React, backend with Flask |

---

## ðŸ—‚ï¸ Project Structure

```
ai_data_logger_chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                  # Main Flask app
â”‚   â”œâ”€â”€ camera_module.py        # Video capture + face/motion detection
â”‚   â”œâ”€â”€ chatbot_module.py       # LLM chatbot engine
â”‚   â”œâ”€â”€ gcp_module.py           # GCP storage uploader
â”‚   â”œâ”€â”€ db_module.py            # Database interaction logic
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ embedder.py         # Embedding generator
â”‚       â”œâ”€â”€ openai_chain.py     # OpenAI query logic
â”‚       â””â”€â”€ ollama_chain.py     # Ollama (LangChain) interface
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx             # Main React app
â”‚   â”‚   â”œâ”€â”€ Chatbot.jsx         # Chat interface
â”‚   â”‚   â”œâ”€â”€ VideoRecorder.jsx   # Live camera
â”‚   â”‚   â””â”€â”€ ImageGallery.jsx    # Log viewer
â”œâ”€â”€ database/schema.sql         # PostgreSQL or MySQL schema
â”œâ”€â”€ ai_models/                  # Embedding/vector store (if local)
â”œâ”€â”€ scripts/embed_all.py        # Index all logs into embedding store
â”œâ”€â”€ docker-compose.yml          # Compose setup
â”œâ”€â”€ README.md                   # This file
```

---

## ðŸ” Environment Variables

Create a `.env` file in `backend/` with the following:

```env
OPENAI_API_KEY=your_openai_api_key
GCP_BUCKET_NAME=your_gcp_bucket
GOOGLE_APPLICATION_CREDENTIALS=path_to_gcp_credentials.json
```

---

## ðŸš€ Deployment Guide

### Backend (Flask) on [Render](https://render.com)
1. Push `/backend/` to GitHub
2. Create new Web Service on Render
3. Set Python build, add environment variables (`.env`)
4. Expose port `5000`

### Frontend (React) on [Vercel](https://vercel.com)
1. Push `/frontend/` to GitHub
2. Import project into Vercel
3. Set backend endpoint in `.env` or config file

---

## ðŸ§ª Run Locally

```bash
# From root
docker-compose up --build
```

Backend will be at: `http://localhost:5000`  
Frontend at: `http://localhost:3000`

---

## ðŸ’¬ Chatbot Query Example

> **You**: "What did the front camera see yesterday at 3 PM?"  
> **Bot**: "Here's an image with a person near the shelf around that time." *(Includes image & text)*

---

## ðŸ›  Requirements

- Docker & Docker Compose
- OpenCV
- Google Cloud SDK (for GCP storage)
- Python 3.9+
- React 18+

---

## ðŸ“š Future Improvements
- Add FAISS/ChromaDB vector search
- Support multi-camera inputs
- Integrate LLM fine-tuning
- Streamlit dashboard for monitoring
